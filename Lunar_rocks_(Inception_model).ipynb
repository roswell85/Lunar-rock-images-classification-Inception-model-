{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lunar rocks (Inception model).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LndNdiuagG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0cd7e10-b675-4df2-8958-4b428933218e"
      },
      "source": [
        "print('Downloading data')\n",
        "print('...')\n",
        "print()\n",
        "!wget http://hck.re/kkBIfM\n",
        "print('Data successfully downloaded')\n",
        "print('##########################################################')\n",
        "\n",
        "print('Loading Libraries..')\n",
        "import zipfile\n",
        "import os,shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "print()\n",
        "print('Libraries successfully loaded')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('EXTRACTING FILES')\n",
        "with zipfile.ZipFile('/content/kkBIfM') as f:\n",
        "  f.extractall()\n",
        "  \n",
        "with zipfile.ZipFile('/content/DataSet/Train Images.zip') as f:\n",
        "  f.extractall()\n",
        "print('# of train images:', len(os.listdir('/content/Train Images/Large'))+\\\n",
        "      len(os.listdir('/content/Train Images/Small'))\n",
        "     )\n",
        "  \n",
        "with zipfile.ZipFile('/content/DataSet/Test Images.zip') as f:\n",
        "  f.extractall()\n",
        "  \n",
        "print('# of test images:',len(os.listdir('/content/Test Images')))\n",
        "print()\n",
        "print('Loading image generator')\n",
        "print()\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1./255.)\n",
        "train_dir ='/content/Train Images'\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "        train_dir, \n",
        "        target_size=(150,150 ),\n",
        "        shuffle = True,\n",
        "        batch_size=50,\n",
        "        class_mode='binary')\n",
        "print('Generator successfully loaded')\n",
        "print()\n",
        "\n",
        "print('Downloading Inception V3 weights..')\n",
        "print()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "print('Weights successfully downloaded')\n",
        "print('##########################################################')\n",
        "\n",
        "print('INCEPTION V3...')  \n",
        "print()\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense  (1, activation='sigmoid')(x)  \n",
        "\n",
        "\n",
        "model = Model( pre_trained_model.input, x)\n",
        "print('Hello world')\n",
        "print()\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "print('Model compiled')\n",
        "print()\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=20,  \n",
        "      epochs=10,\n",
        "      verbose=2)\n",
        "print('Model training completed')\n",
        "print('##########################################################')\n",
        "\n",
        "print('Moving test files to \"test\" dir.')\n",
        "\n",
        "print()\n",
        "test_dir = '/content/Test Images/'\n",
        "\n",
        "!mkdir '/content/Test Images/test'\n",
        "print('Test Data generator director has been created; ',test_dir+'test')\n",
        "\n",
        "\n",
        "for i in os.listdir(test_dir):\n",
        "  if i!='test':\n",
        "    shutil.move(test_dir+i,test_dir+'test/'+i)\n",
        "print('All files successfully moved')\n",
        "print()\n",
        "\n",
        "print('Testing..')\n",
        "print()\n",
        "test_dir = '/content/Test Images/'\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        shuffle = False,\n",
        "        batch_size=32, \n",
        "        class_mode=None,)\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "print('Prediction')\n",
        "predict = model.predict_generator(test_generator,np.ceil(nb_samples/32))\n",
        "predicted_classes = [1 if i>0.5 else 0 for i in predict]\n",
        "print('Done!')\n",
        "print()\n",
        "\n",
        "print('Processing output..')\n",
        "print()\n",
        "keys = os.listdir(test_dir+'test')\n",
        "keys = [i for i in keys if i!='.ipynb_checkpoints']\n",
        "\n",
        "df = pd.read_csv('/content/DataSet/test.csv')\n",
        "test_files = df.Image_File.tolist()\n",
        "_ = []\n",
        "for i in test_files:\n",
        "  \n",
        "  if i in keys:\n",
        "    _.append(i)\n",
        "  else:\n",
        "    break;\n",
        "    print('ERROR: MISSING FILE !')\n",
        "    \n",
        "dic = dict(zip(_,predicted_classes))\n",
        "df['Class'] = df['Image_File'].apply(lambda x : dic[x])\n",
        "df.to_csv('submission_file.csv',index=False)\n",
        "print('Test predictions saved to submission_file.csv')\n",
        "df\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data\n",
            "...\n",
            "\n",
            "--2019-10-26 00:17:56--  http://hck.re/kkBIfM\n",
            "Resolving hck.re (hck.re)... 54.169.227.143, 18.136.192.20, 54.169.47.64\n",
            "Connecting to hck.re (hck.re)|54.169.227.143|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Location: https://he-public-data.s3-ap-southeast-1.amazonaws.com/DataSet.zip [following]\n",
            "--2019-10-26 00:17:57--  https://he-public-data.s3-ap-southeast-1.amazonaws.com/DataSet.zip\n",
            "Resolving he-public-data.s3-ap-southeast-1.amazonaws.com (he-public-data.s3-ap-southeast-1.amazonaws.com)... 52.219.124.47\n",
            "Connecting to he-public-data.s3-ap-southeast-1.amazonaws.com (he-public-data.s3-ap-southeast-1.amazonaws.com)|52.219.124.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 733209860 (699M) [application/zip]\n",
            "Saving to: ‘kkBIfM’\n",
            "\n",
            "kkBIfM              100%[===================>] 699.24M  13.6MB/s    in 54s     \n",
            "\n",
            "2019-10-26 00:18:52 (13.0 MB/s) - ‘kkBIfM’ saved [733209860/733209860]\n",
            "\n",
            "Data successfully downloaded\n",
            "##########################################################\n",
            "Loading Libraries..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Libraries successfully loaded\n",
            "EXTRACTING FILES\n",
            "# of train images: 11998\n",
            "# of test images: 7534\n",
            "\n",
            "Loading image generator\n",
            "\n",
            "Found 11998 images belonging to 2 classes.\n",
            "Generator successfully loaded\n",
            "\n",
            "Downloading Inception V3 weights..\n",
            "\n",
            "--2019-10-26 00:19:07--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.217.128, 2607:f8b0:400c:c13::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.217.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  93.1MB/s    in 0.9s    \n",
            "\n",
            "2019-10-26 00:19:13 (93.1 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "Weights successfully downloaded\n",
            "##########################################################\n",
            "INCEPTION V3...\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "last layer output shape:  (None, 7, 7, 768)\n",
            "Hello world\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model compiled\n",
            "\n",
            "Epoch 1/10\n",
            "20/20 - 55s - loss: 0.3691 - acc: 0.8490\n",
            "Epoch 2/10\n",
            "20/20 - 52s - loss: 0.1992 - acc: 0.9380\n",
            "Epoch 3/10\n",
            "20/20 - 51s - loss: 0.1304 - acc: 0.9630\n",
            "Epoch 4/10\n",
            "20/20 - 52s - loss: 0.1078 - acc: 0.9680\n",
            "Epoch 5/10\n",
            "20/20 - 52s - loss: 0.0901 - acc: 0.9720\n",
            "Epoch 6/10\n",
            "20/20 - 52s - loss: 0.0845 - acc: 0.9700\n",
            "Epoch 7/10\n",
            "20/20 - 52s - loss: 0.0960 - acc: 0.9640\n",
            "Epoch 8/10\n",
            "20/20 - 51s - loss: 0.0931 - acc: 0.9720\n",
            "Epoch 9/10\n",
            "20/20 - 51s - loss: 0.0780 - acc: 0.9760\n",
            "Epoch 10/10\n",
            "20/20 - 52s - loss: 0.0536 - acc: 0.9860\n",
            "Model training completed\n",
            "##########################################################\n",
            "Moving test files to \"test\" dir.\n",
            "\n",
            "Test Data generator director has been created;  /content/Test Images/test\n",
            "All files successfully moved\n",
            "\n",
            "Testing..\n",
            "\n",
            "Found 7534 images belonging to 1 classes.\n",
            "Prediction\n",
            "Done!\n",
            "\n",
            "Processing output..\n",
            "\n",
            "Test predictions saved to submission_file.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image_File</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lg 988 (1).png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lg 988 (10).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lg 988 (100).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lg 988 (101).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lg 988 (102).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7529</th>\n",
              "      <td>lg99 (95).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7530</th>\n",
              "      <td>lg99 (96).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7531</th>\n",
              "      <td>lg99 (97).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7532</th>\n",
              "      <td>lg99 (98).png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7533</th>\n",
              "      <td>lg99 (99).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7534 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Image_File  Class\n",
              "0       lg 988 (1).png      1\n",
              "1      lg 988 (10).png      0\n",
              "2     lg 988 (100).png      0\n",
              "3     lg 988 (101).png      0\n",
              "4     lg 988 (102).png      0\n",
              "...                ...    ...\n",
              "7529     lg99 (95).png      0\n",
              "7530     lg99 (96).png      0\n",
              "7531     lg99 (97).png      0\n",
              "7532     lg99 (98).png      1\n",
              "7533     lg99 (99).png      0\n",
              "\n",
              "[7534 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2U01hZVbDjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip freeze > requirements.txt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noS0adH5kZts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}