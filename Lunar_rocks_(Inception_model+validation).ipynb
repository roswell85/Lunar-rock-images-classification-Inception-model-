{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lunar rocks (Inception model+validation).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JRRnwNXBPa5",
        "colab_type": "code",
        "outputId": "f2b8def7-412b-4db5-aa7b-36abd33e08f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Downloading data')\n",
        "print('...')\n",
        "print()\n",
        "!wget http://hck.re/kkBIfM\n",
        "print('Data successfully downloaded')\n",
        "print('##########################################################')\n",
        "\n",
        "print('Loading Libraries..')\n",
        "import zipfile\n",
        "import os,shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('EXTRACTING FILES')\n",
        "with zipfile.ZipFile('/content/kkBIfM') as f:\n",
        "  f.extractall()\n",
        "  \n",
        "with zipfile.ZipFile('/content/DataSet/Train Images.zip') as f:\n",
        "  f.extractall()\n",
        "print('# of train images:', len(os.listdir('/content/Train Images/Large'))+\\\n",
        "      len(os.listdir('/content/Train Images/Small'))\n",
        "     )\n",
        "  \n",
        "with zipfile.ZipFile('/content/DataSet/Test Images.zip') as f:\n",
        "  f.extractall()\n",
        "  \n",
        "print('# of test images:',len(os.listdir('/content/Test Images')))\n",
        "print()\n",
        "\n",
        "print('Creating Validation dir.')\n",
        "print()\n",
        "train_dir = '/content/Train Images/'\n",
        "test_dir = '/content/Test Images/'\n",
        "!mkdir '/content/Validation Images'\n",
        "val_dir = '/content/Validation Images/'\n",
        "!mkdir '/content/Validation Images/Large/'\n",
        "!mkdir '/content/Validation Images/Small/'\n",
        "index = np.random.choice(range(5999),size=[1000],replace=False)\n",
        "val_small = np.array(os.listdir(train_dir+'Small'))[index]\n",
        "#val_small\n",
        "val_large =  np.array(os.listdir(train_dir+'Large'))[index]\n",
        "\n",
        "\n",
        "for i in val_small:\n",
        "  shutil.move(train_dir+'Small/'+i,val_dir+'Small/'+i)\n",
        "  \n",
        "for i in val_large:\n",
        "  shutil.move(train_dir+'Large/'+i,val_dir+'Large/'+i)\n",
        "  \n",
        "\n",
        "\n",
        "print('Loading train generator')\n",
        "print()\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1./255.)\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "        train_dir, \n",
        "        target_size=(150,150 ),\n",
        "        shuffle = True,\n",
        "        batch_size=50,\n",
        "        class_mode='binary')\n",
        "\n",
        "print('Loading validation generator')\n",
        "print()\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale=1./255.)\n",
        "val_generator = train_gen.flow_from_directory(\n",
        "        val_dir, \n",
        "        target_size=(150,150 ),\n",
        "        shuffle = True,\n",
        "        batch_size=50,\n",
        "        class_mode='binary')\n",
        "\n",
        "print('Downloading Inception V3 weights..')\n",
        "print()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "  \n",
        "print('##########################################################')\n",
        "\n",
        "print('INCEPTION V3...')  \n",
        "print()\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "#print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "x = layers.Dense  (1, activation='sigmoid')(x)  \n",
        "\n",
        "\n",
        "model = Model( pre_trained_model.input, x)\n",
        "print('Hello world')\n",
        "print()\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "print('Model compiled')\n",
        "print()\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      validation_data= val_generator,   \n",
        "      steps_per_epoch=20,  \n",
        "      epochs=10,\n",
        "      verbose=2)\n",
        "print('Model training completed')\n",
        "print('##########################################################')\n",
        "\n",
        "print('Moving test files to \"test\" dir.')\n",
        "\n",
        "print()\n",
        "test_dir = '/content/Test Images/'\n",
        "\n",
        "!mkdir '/content/Test Images/test'\n",
        "print('Test Data generator director has been created; ',test_dir+'test')\n",
        "print()\n",
        "\n",
        "\n",
        "for i in os.listdir(test_dir):\n",
        "  if i!='test':\n",
        "    shutil.move(test_dir+i,test_dir+'test/'+i)\n",
        "\n",
        "print('Testing..')\n",
        "print()\n",
        "test_dir = '/content/Test Images/'\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        shuffle = False,\n",
        "        batch_size=32, \n",
        "        class_mode=None,)\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "print('Prediction')\n",
        "predict = model.predict_generator(test_generator,np.ceil(nb_samples/32))\n",
        "predicted_classes = [1 if i>0.5 else 0 for i in predict]\n",
        "\n",
        "\n",
        "print('Processing output..')\n",
        "print()\n",
        "keys = os.listdir(test_dir+'test')\n",
        "keys = [i for i in keys if i!='.ipynb_checkpoints']\n",
        "\n",
        "df = pd.read_csv('/content/DataSet/test.csv')\n",
        "test_files = df.Image_File.tolist()\n",
        "_ = []\n",
        "for i in test_files:\n",
        "  \n",
        "  if i in keys:\n",
        "    _.append(i)\n",
        "  else:\n",
        "    break;\n",
        "    print('ERROR: MISSING FILE !')\n",
        "    \n",
        "dic = dict(zip(_,predicted_classes))\n",
        "df['Class'] = df['Image_File'].apply(lambda x : dic[x])\n",
        "df.to_csv('submission_file.csv',index=False)\n",
        "print('Test predictions saved to submission_file.csv')\n",
        "df\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data\n",
            "...\n",
            "\n",
            "--2019-10-27 02:03:46--  http://hck.re/kkBIfM\n",
            "Resolving hck.re (hck.re)... 18.136.192.20, 54.169.227.143, 54.169.47.64\n",
            "Connecting to hck.re (hck.re)|18.136.192.20|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Location: https://he-public-data.s3-ap-southeast-1.amazonaws.com/DataSet.zip [following]\n",
            "--2019-10-27 02:03:47--  https://he-public-data.s3-ap-southeast-1.amazonaws.com/DataSet.zip\n",
            "Resolving he-public-data.s3-ap-southeast-1.amazonaws.com (he-public-data.s3-ap-southeast-1.amazonaws.com)... 52.219.128.11\n",
            "Connecting to he-public-data.s3-ap-southeast-1.amazonaws.com (he-public-data.s3-ap-southeast-1.amazonaws.com)|52.219.128.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 733209860 (699M) [application/zip]\n",
            "Saving to: ‘kkBIfM’\n",
            "\n",
            "kkBIfM              100%[===================>] 699.24M  10.5MB/s    in 70s     \n",
            "\n",
            "2019-10-27 02:04:58 (9.99 MB/s) - ‘kkBIfM’ saved [733209860/733209860]\n",
            "\n",
            "Data successfully downloaded\n",
            "##########################################################\n",
            "Loading Libraries..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "EXTRACTING FILES\n",
            "# of train images: 11998\n",
            "# of test images: 7534\n",
            "\n",
            "Creating Validation dir.\n",
            "\n",
            "Loading train generator\n",
            "\n",
            "Found 9998 images belonging to 2 classes.\n",
            "Loading validation generator\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Downloading Inception V3 weights..\n",
            "\n",
            "--2019-10-27 02:05:18--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.184.128, 2a00:1450:400c:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.184.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  30.5MB/s    in 2.7s    \n",
            "\n",
            "2019-10-27 02:05:21 (30.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "##########################################################\n",
            "INCEPTION V3...\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Hello world\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model compiled\n",
            "\n",
            "Epoch 1/10\n",
            "Epoch 1/10\n",
            "40/20 - 14s - loss: 0.4743 - acc: 0.7900\n",
            "20/20 - 24s - loss: 0.4383 - acc: 0.8120 - val_loss: 0.4434 - val_acc: 0.7900\n",
            "Epoch 2/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 0.4758 - acc: 0.7875\n",
            "20/20 - 16s - loss: 0.1907 - acc: 0.9500 - val_loss: 0.4882 - val_acc: 0.7875\n",
            "Epoch 3/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 0.3718 - acc: 0.8295\n",
            "20/20 - 16s - loss: 0.1477 - acc: 0.9480 - val_loss: 0.3733 - val_acc: 0.8295\n",
            "Epoch 4/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 0.4838 - acc: 0.7820\n",
            "20/20 - 16s - loss: 0.1238 - acc: 0.9690 - val_loss: 0.4927 - val_acc: 0.7820\n",
            "Epoch 5/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 0.7315 - acc: 0.7140\n",
            "20/20 - 16s - loss: 0.1036 - acc: 0.9750 - val_loss: 0.7858 - val_acc: 0.7140\n",
            "Epoch 6/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 0.7344 - acc: 0.7000\n",
            "20/20 - 16s - loss: 0.0697 - acc: 0.9820 - val_loss: 0.8478 - val_acc: 0.7000\n",
            "Epoch 7/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 1.0548 - acc: 0.6655\n",
            "20/20 - 16s - loss: 0.0826 - acc: 0.9710 - val_loss: 1.2092 - val_acc: 0.6655\n",
            "Epoch 8/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 1.2491 - acc: 0.6520\n",
            "20/20 - 16s - loss: 0.0646 - acc: 0.9790 - val_loss: 1.3531 - val_acc: 0.6520\n",
            "Epoch 9/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 1.0401 - acc: 0.6910\n",
            "20/20 - 16s - loss: 0.0739 - acc: 0.9739 - val_loss: 1.0720 - val_acc: 0.6910\n",
            "Epoch 10/10\n",
            "Epoch 1/10\n",
            "40/20 - 13s - loss: 1.4214 - acc: 0.6525\n",
            "20/20 - 16s - loss: 0.0783 - acc: 0.9740 - val_loss: 1.4616 - val_acc: 0.6525\n",
            "Model training completed\n",
            "##########################################################\n",
            "Moving test files to \"test\" dir.\n",
            "\n",
            "Test Data generator director has been created;  /content/Test Images/test\n",
            "\n",
            "Testing..\n",
            "\n",
            "Found 7534 images belonging to 1 classes.\n",
            "Prediction\n",
            "Processing output..\n",
            "\n",
            "Test predictions saved to submission_file.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image_File</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lg 988 (1).png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>lg 988 (10).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lg 988 (100).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lg 988 (101).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lg 988 (102).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7529</th>\n",
              "      <td>lg99 (95).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7530</th>\n",
              "      <td>lg99 (96).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7531</th>\n",
              "      <td>lg99 (97).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7532</th>\n",
              "      <td>lg99 (98).png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7533</th>\n",
              "      <td>lg99 (99).png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7534 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Image_File  Class\n",
              "0       lg 988 (1).png      1\n",
              "1      lg 988 (10).png      0\n",
              "2     lg 988 (100).png      0\n",
              "3     lg 988 (101).png      0\n",
              "4     lg 988 (102).png      0\n",
              "...                ...    ...\n",
              "7529     lg99 (95).png      0\n",
              "7530     lg99 (96).png      0\n",
              "7531     lg99 (97).png      0\n",
              "7532     lg99 (98).png      1\n",
              "7533     lg99 (99).png      0\n",
              "\n",
              "[7534 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}