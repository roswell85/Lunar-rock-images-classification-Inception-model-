{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GH Lunar rocks classification ( model+validation).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JRRnwNXBPa5",
        "colab_type": "code",
        "outputId": "27d20a17-58c9-40d8-8a98-2446e4439dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print('Downloading data')\n",
        "print('...')\n",
        "print()\n",
        "!wget http://hck.re/kkBIfM\n",
        "print('Data successfully downloaded')\n",
        "print('##########################################################')\n",
        "\n",
        "print('Loading Libraries..')\n",
        "import zipfile\n",
        "import os,shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('EXTRACTING FILES')\n",
        "with zipfile.ZipFile('/content/kkBIfM') as f:\n",
        "  f.extractall()\n",
        "  \n",
        "with zipfile.ZipFile('/content/DataSet/Train Images.zip') as f:\n",
        "  f.extractall()\n",
        "print('# of train images:', len(os.listdir('/content/Train Images/Large'))+\\\n",
        "      len(os.listdir('/content/Train Images/Small'))\n",
        "     )\n",
        "  \n",
        "with zipfile.ZipFile('/content/DataSet/Test Images.zip') as f:\n",
        "  f.extractall()\n",
        "  \n",
        "print('# of test images:',len(os.listdir('/content/Test Images')))\n",
        "print()\n",
        "\n",
        "print('Creating Validation dir.')\n",
        "print()\n",
        "train_dir = '/content/Train Images/'\n",
        "test_dir = '/content/Test Images/'\n",
        "!mkdir '/content/Validation Images'\n",
        "val_dir = '/content/Validation Images/'\n",
        "!mkdir '/content/Validation Images/Large/'\n",
        "!mkdir '/content/Validation Images/Small/'\n",
        "index = np.random.choice(range(5999),size=[1000],replace=False)\n",
        "val_small = np.array(os.listdir(train_dir+'Small'))[index]\n",
        "#val_small\n",
        "val_large =  np.array(os.listdir(train_dir+'Large'))[index]\n",
        "\n",
        "\n",
        "for i in val_small:\n",
        "  shutil.move(train_dir+'Small/'+i,val_dir+'Small/'+i)\n",
        "  \n",
        "for i in val_large:\n",
        "  shutil.move(train_dir+'Large/'+i,val_dir+'Large/'+i)\n",
        "  \n",
        "\n",
        "\n",
        "print('Loading train generator')\n",
        "print()\n",
        "\n",
        "#train_gen = ImageDataGenerator(rescale=1./255.)\n",
        "#train_gen = ImageDataGenerator(rescale=1./255)\n",
        "train_gen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "train_generator = train_gen.flow_from_directory(\n",
        "        train_dir, \n",
        "        target_size=(300,400 ),\n",
        "        shuffle = True,\n",
        "        batch_size=50,\n",
        "        class_mode='binary')\n",
        "\n",
        "print('Loading validation generator')\n",
        "print()\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale=1./255.)\n",
        "val_generator = train_gen.flow_from_directory(\n",
        "        val_dir, \n",
        "        target_size=(300,400),\n",
        "        shuffle = True,\n",
        "        batch_size=50,\n",
        "        class_mode='binary')\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(300,400, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "   tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "print('Hello world')\n",
        "print()\n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "print('Model compiled')\n",
        "print()\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      validation_data= val_generator,   \n",
        "      steps_per_epoch=20,  \n",
        "      epochs=10,\n",
        "      verbose=2)\n",
        "print('Model training completed')\n",
        "print('##########################################################')\n",
        "print('Validation; objective: F1 score')\n",
        "print()\n",
        "filenames = val_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "print('Prediction')\n",
        "#predict = model.predict_generator( val_generator,np.ceil(nb_samples/32))\n",
        "predict = model.predict_generator(val_generator)\n",
        "predicted_classes = [1 if i>0.5 else 0 for i in predict]\n",
        "true_y = val_generator.filenames\n",
        "true_y = [i.split('/')[0] for i in true_y]\n",
        "true_y = [0 if i=='Large' else 1 for i in true_y]\n",
        "from sklearn.metrics import f1_score,accuracy_score,precision_score,roc_auc_score\n",
        "print('f1 score = ',100*f1_score(true_y,predicted_classes))\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data\n",
            "...\n",
            "\n",
            "--2019-10-30 22:33:10--  http://hck.re/kkBIfM\n",
            "Resolving hck.re (hck.re)... 54.169.227.143, 18.136.192.20, 54.169.47.64\n",
            "Connecting to hck.re (hck.re)|54.169.227.143|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Cookie coming from hck.re attempted to set domain to hackerearth.com\n",
            "Location: https://he-public-data.s3-ap-southeast-1.amazonaws.com/DataSet.zip [following]\n",
            "--2019-10-30 22:33:16--  https://he-public-data.s3-ap-southeast-1.amazonaws.com/DataSet.zip\n",
            "Resolving he-public-data.s3-ap-southeast-1.amazonaws.com (he-public-data.s3-ap-southeast-1.amazonaws.com)... 52.219.48.51\n",
            "Connecting to he-public-data.s3-ap-southeast-1.amazonaws.com (he-public-data.s3-ap-southeast-1.amazonaws.com)|52.219.48.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 733209860 (699M) [application/zip]\n",
            "Saving to: ‘kkBIfM’\n",
            "\n",
            "kkBIfM              100%[===================>] 699.24M  16.0MB/s    in 46s     \n",
            "\n",
            "2019-10-30 22:34:03 (15.2 MB/s) - ‘kkBIfM’ saved [733209860/733209860]\n",
            "\n",
            "Data successfully downloaded\n",
            "##########################################################\n",
            "Loading Libraries..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "EXTRACTING FILES\n",
            "# of train images: 11998\n",
            "# of test images: 7534\n",
            "\n",
            "Creating Validation dir.\n",
            "\n",
            "Loading train generator\n",
            "\n",
            "Found 9998 images belonging to 2 classes.\n",
            "Loading validation generator\n",
            "\n",
            "Found 2000 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Hello world\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model compiled\n",
            "\n",
            "Epoch 1/10\n",
            "Epoch 1/10\n",
            "40/20 - 78s - loss: 0.5560 - acc: 0.7630\n",
            "20/20 - 113s - loss: 0.8656 - acc: 0.6320 - val_loss: 0.5504 - val_acc: 0.7630\n",
            "Epoch 2/10\n",
            "Epoch 1/10\n",
            "40/20 - 77s - loss: 0.4371 - acc: 0.8225\n",
            "20/20 - 96s - loss: 0.5233 - acc: 0.7670 - val_loss: 0.4323 - val_acc: 0.8225\n",
            "Epoch 3/10\n",
            "Epoch 1/10\n",
            "40/20 - 77s - loss: 0.2590 - acc: 0.9015\n",
            "20/20 - 96s - loss: 0.4702 - acc: 0.8317 - val_loss: 0.2453 - val_acc: 0.9015\n",
            "Epoch 4/10\n",
            "Epoch 1/10\n",
            "40/20 - 78s - loss: 0.2716 - acc: 0.9330\n",
            "20/20 - 95s - loss: 0.5834 - acc: 0.8970 - val_loss: 0.2712 - val_acc: 0.9330\n",
            "Epoch 5/10\n",
            "Epoch 1/10\n",
            "40/20 - 77s - loss: 0.0848 - acc: 0.9665\n",
            "20/20 - 95s - loss: 0.1683 - acc: 0.9420 - val_loss: 0.0884 - val_acc: 0.9665\n",
            "Epoch 6/10\n",
            "Epoch 1/10\n",
            "40/20 - 77s - loss: 0.1693 - acc: 0.9840\n",
            "20/20 - 96s - loss: 0.2548 - acc: 0.9320 - val_loss: 0.1781 - val_acc: 0.9840\n",
            "Epoch 7/10\n",
            "Epoch 1/10\n",
            "40/20 - 79s - loss: 0.0903 - acc: 0.9770\n",
            "20/20 - 97s - loss: 0.2777 - acc: 0.9380 - val_loss: 0.0817 - val_acc: 0.9770\n",
            "Epoch 8/10\n",
            "Epoch 1/10\n",
            "40/20 - 77s - loss: 0.3565 - acc: 0.9120\n",
            "20/20 - 96s - loss: 0.0580 - acc: 0.9850 - val_loss: 0.3369 - val_acc: 0.9120\n",
            "Epoch 9/10\n",
            "Epoch 1/10\n",
            "40/20 - 79s - loss: 0.2588 - acc: 0.9625\n",
            "20/20 - 97s - loss: 0.3146 - acc: 0.9380 - val_loss: 0.2537 - val_acc: 0.9625\n",
            "Epoch 10/10\n",
            "Epoch 1/10\n",
            "40/20 - 78s - loss: 0.0660 - acc: 0.9815\n",
            "20/20 - 96s - loss: 0.0771 - acc: 0.9810 - val_loss: 0.0470 - val_acc: 0.9815\n",
            "Model training completed\n",
            "##########################################################\n",
            "Validation; objective: F1 score\n",
            "\n",
            "Prediction\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "f1 score =  49.235474006116206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/_pytest/mark/structures.py:426: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
            "  @attr.s(cmp=False, hash=False)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_skweXlO-b1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9bbc873-d8e4-4ab1-b5ff-d07e4a269fa8"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300,400, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3),padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "   tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3),padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    #tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1024, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "print('Hello world')\n",
        "print()\n",
        "sgd = SGD(nesterov=True)\n",
        "rms = RMSprop(lr=0.001)\n",
        "adam = Adam()\n",
        "model.compile(optimizer = adam, \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "print('Model compiled')\n",
        "print()\n",
        "\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      validation_data= val_generator,   \n",
        "      steps_per_epoch=20,  \n",
        "      epochs=20,\n",
        "      verbose=2)\n",
        "print('Model training completed')\n",
        "print('##########################################################')\n",
        "print('Validation; objective: F1 score')\n",
        "print()\n",
        "filenames = val_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "print('Prediction')\n",
        "#predict = model.predict_generator( val_generator,np.ceil(nb_samples/32))\n",
        "predict = model.predict_generator(val_generator)\n",
        "predicted_classes = [1 if i>0.5 else 0 for i in predict]\n",
        "true_y = val_generator.filenames\n",
        "true_y = [i.split('/')[0] for i in true_y]\n",
        "true_y = [0 if i=='Large' else 1 for i in true_y]\n",
        "from sklearn.metrics import f1_score,accuracy_score,precision_score,roc_auc_score\n",
        "print('f1 score = ',100*f1_score(true_y,predicted_classes))\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello world\n",
            "\n",
            "Model compiled\n",
            "\n",
            "Epoch 1/20\n",
            "Epoch 1/20\n",
            "40/20 - 78s - loss: 0.5766 - acc: 0.7525\n",
            "20/20 - 111s - loss: 0.6387 - acc: 0.6080 - val_loss: 0.5370 - val_acc: 0.7525\n",
            "Epoch 2/20\n",
            "Epoch 1/20\n",
            "40/20 - 77s - loss: 0.2500 - acc: 0.9255\n",
            "20/20 - 94s - loss: 0.3567 - acc: 0.8570 - val_loss: 0.2252 - val_acc: 0.9255\n",
            "Epoch 3/20\n",
            "Epoch 1/20\n",
            "40/20 - 78s - loss: 0.1589 - acc: 0.9105\n",
            "20/20 - 95s - loss: 0.1751 - acc: 0.9300 - val_loss: 0.1956 - val_acc: 0.9105\n",
            "Epoch 4/20\n",
            "Epoch 1/20\n",
            "40/20 - 77s - loss: 0.0933 - acc: 0.9640\n",
            "20/20 - 94s - loss: 0.1208 - acc: 0.9500 - val_loss: 0.1141 - val_acc: 0.9640\n",
            "Epoch 5/20\n",
            "Epoch 1/20\n",
            "40/20 - 78s - loss: 0.1077 - acc: 0.9735\n",
            "20/20 - 95s - loss: 0.1012 - acc: 0.9619 - val_loss: 0.0926 - val_acc: 0.9735\n",
            "Epoch 6/20\n",
            "Epoch 1/20\n",
            "40/20 - 77s - loss: 0.0797 - acc: 0.9845\n",
            "20/20 - 94s - loss: 0.0993 - acc: 0.9650 - val_loss: 0.0610 - val_acc: 0.9845\n",
            "Epoch 7/20\n",
            "Epoch 1/20\n",
            "40/20 - 77s - loss: 0.1733 - acc: 0.9625\n",
            "20/20 - 94s - loss: 0.0891 - acc: 0.9770 - val_loss: 0.1098 - val_acc: 0.9625\n",
            "Epoch 8/20\n",
            "Epoch 1/20\n",
            "40/20 - 77s - loss: 0.0299 - acc: 0.9870\n",
            "20/20 - 94s - loss: 0.0985 - acc: 0.9720 - val_loss: 0.0457 - val_acc: 0.9870\n",
            "Epoch 9/20\n",
            "Epoch 1/20\n",
            "40/20 - 76s - loss: 0.2513 - acc: 0.8865\n",
            "20/20 - 93s - loss: 0.0524 - acc: 0.9800 - val_loss: 0.2162 - val_acc: 0.8865\n",
            "Epoch 10/20\n",
            "Epoch 1/20\n",
            "40/20 - 76s - loss: 0.1143 - acc: 0.9520\n",
            "20/20 - 93s - loss: 0.0908 - acc: 0.9730 - val_loss: 0.1494 - val_acc: 0.9520\n",
            "Epoch 11/20\n",
            "Epoch 1/20\n",
            "40/20 - 78s - loss: 0.0509 - acc: 0.9790\n",
            "20/20 - 95s - loss: 0.0795 - acc: 0.9770 - val_loss: 0.0753 - val_acc: 0.9790\n",
            "Epoch 12/20\n",
            "Epoch 1/20\n",
            "40/20 - 77s - loss: 0.0197 - acc: 0.9910\n",
            "20/20 - 94s - loss: 0.0371 - acc: 0.9880 - val_loss: 0.0256 - val_acc: 0.9910\n",
            "Epoch 13/20\n",
            "Epoch 1/20\n",
            "40/20 - 76s - loss: 0.0168 - acc: 0.9930\n",
            "20/20 - 93s - loss: 0.0231 - acc: 0.9930 - val_loss: 0.0219 - val_acc: 0.9930\n",
            "Epoch 14/20\n",
            "Epoch 1/20\n",
            "40/20 - 77s - loss: 0.0359 - acc: 0.9920\n",
            "20/20 - 94s - loss: 0.0154 - acc: 0.9940 - val_loss: 0.0231 - val_acc: 0.9920\n",
            "Epoch 15/20\n",
            "Epoch 1/20\n",
            "40/20 - 78s - loss: 0.0214 - acc: 0.9940\n",
            "20/20 - 95s - loss: 0.0169 - acc: 0.9920 - val_loss: 0.0144 - val_acc: 0.9940\n",
            "Epoch 16/20\n",
            "Epoch 1/20\n",
            "40/20 - 78s - loss: 0.0269 - acc: 0.9895\n",
            "20/20 - 95s - loss: 0.0239 - acc: 0.9920 - val_loss: 0.0406 - val_acc: 0.9895\n",
            "Epoch 17/20\n",
            "Epoch 1/20\n",
            "40/20 - 77s - loss: 0.0208 - acc: 0.9925\n",
            "20/20 - 95s - loss: 0.0376 - acc: 0.9890 - val_loss: 0.0219 - val_acc: 0.9925\n",
            "Epoch 18/20\n",
            "Epoch 1/20\n",
            "40/20 - 78s - loss: 0.4140 - acc: 0.9520\n",
            "20/20 - 95s - loss: 0.0527 - acc: 0.9880 - val_loss: 0.4779 - val_acc: 0.9520\n",
            "Epoch 19/20\n",
            "Epoch 1/20\n",
            "40/20 - 76s - loss: 0.0860 - acc: 0.9745\n",
            "20/20 - 93s - loss: 0.0931 - acc: 0.9740 - val_loss: 0.0998 - val_acc: 0.9745\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "40/20 - 76s - loss: 0.0484 - acc: 0.9845\n",
            "20/20 - 93s - loss: 0.0502 - acc: 0.9840 - val_loss: 0.0428 - val_acc: 0.9845\n",
            "Model training completed\n",
            "##########################################################\n",
            "Validation; objective: F1 score\n",
            "\n",
            "Prediction\n",
            "f1 score =  49.59432048681542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TL0x0FfmCQMa",
        "colab": {}
      },
      "source": [
        "\n",
        "print('Moving test files to \"test\" dir.')\n",
        "\n",
        "print()\n",
        "test_dir = '/content/Test Images/'\n",
        "\n",
        "!mkdir '/content/Test Images/test'\n",
        "print('Test Data generator director has been created; ',test_dir+'test')\n",
        "print()\n",
        "\n",
        "\n",
        "for i in os.listdir(test_dir):\n",
        "  if i!='test':\n",
        "    shutil.move(test_dir+i,test_dir+'test/'+i)\n",
        "\n",
        "print('Testing..')\n",
        "print()\n",
        "test_dir = '/content/Test Images/'\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(150, 150),\n",
        "        shuffle = False,\n",
        "        batch_size=32, \n",
        "        class_mode=None,)\n",
        "\n",
        "filenames = test_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "print('Prediction')\n",
        "predict = model.predict_generator(test_generator,np.ceil(nb_samples/32))\n",
        "predicted_classes = [1 if i>0.5 else 0 for i in predict]\n",
        "\n",
        "\n",
        "print('Processing output..')\n",
        "print()\n",
        "keys = os.listdir(test_dir+'test')\n",
        "keys = [i for i in keys if i!='.ipynb_checkpoints']\n",
        "\n",
        "df = pd.read_csv('/content/DataSet/test.csv')\n",
        "test_files = df.Image_File.tolist()\n",
        "_ = []\n",
        "for i in test_files:\n",
        "  \n",
        "  if i in keys:\n",
        "    _.append(i)\n",
        "  else:\n",
        "    break;\n",
        "    print('ERROR: MISSING FILE !')\n",
        "    \n",
        "dic = dict(zip(_,predicted_classes))\n",
        "df['Class'] = df['Image_File'].apply(lambda x : dic[x])\n",
        "df.to_csv('submission_file.csv',index=False)\n",
        "print('Test predictions saved to submission_file.csv')\n",
        "df\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}